/**
 * Core types for the LoRa Dataset Builder application
 * 
 * This module defines the primary data structures used throughout the application
 * for managing images, captions, user settings, and dataset exports.
 * 
 * @fileoverview Type definitions for LoRa Dataset Builder
 * @version 1.0.0
 */

/**
 * Represents a caption candidate generated by a vision model provider
 * 
 * Each image can have multiple caption candidates from different AI providers.
 * Users can select the best caption or edit it to create their final dataset.
 * 
 * @interface CaptionCandidate
 * @example
 * ```typescript
 * const candidate: CaptionCandidate = {
 *   modelId: "openai:gpt-4o-mini",
 *   caption: "A golden retriever playing in a park",
 *   createdAt: Date.now(),
 *   latencyMs: 1250,
 *   tokensUsed: 15
 * };
 * ```
 */
export interface CaptionCandidate {
  /** Unique identifier for the AI model (e.g., "openai:gpt-4o-mini", "gemini:gemini-2.0-flash") */
  modelId: string;
  /** The generated caption text */
  caption: string;
  /** Timestamp when the caption was generated (epoch milliseconds) */
  createdAt: number;
  /** Time taken to generate the caption in milliseconds */
  latencyMs?: number;
  /** Number of tokens consumed by the AI model */
  tokensUsed?: number;
  /** Error message if caption generation failed */
  error?: string;
}

/**
 * Represents an image document stored in Firestore
 * 
 * This is the primary data structure for images in the application.
 * Each image goes through a lifecycle: pending → processing → complete/error.
 * 
 * @interface ImageDoc
 * @example
 * ```typescript
 * const image: ImageDoc = {
 *   id: "img_123",
 *   filename: "dog.jpg",
 *   storagePath: "gs://bucket/uploads/user123/img_123/dog.jpg",
 *   downloadURL: "https://storage.googleapis.com/...",
 *   status: "complete",
 *   candidates: [candidate1, candidate2],
 *   selectedIndex: 0,
 *   createdAt: Date.now(),
 *   updatedAt: Date.now()
 * };
 * ```
 */
export interface ImageDoc {
  /** Unique identifier for the image document */
  id: string;
  /** Original filename of the uploaded image */
  filename: string;
  /** Firebase Storage path (gs://bucket/path format) */
  storagePath: string;
  /** Public download URL for the image (signed URL) */
  downloadURL: string;
  /** Optional base64 encoded image data for small images */
  base64?: string;
  /** Current processing status of the image */
  status: 'pending' | 'processing' | 'complete' | 'error';
  /** Error message if processing failed */
  error?: string;
  /** Array of caption candidates from different AI providers */
  candidates: CaptionCandidate[];
  /** Index of the selected caption in the candidates array */
  selectedIndex: number | null;
  /** User's custom text override for the selected caption */
  selectedTextOverride?: string;
  /** User ID who owns this image (for authentication) */
  userId?: string;
  /** Timestamp when the image was uploaded (epoch milliseconds) */
  createdAt: number;
  /** Timestamp when the image was last updated (epoch milliseconds) */
  updatedAt: number;
}

/**
 * User settings and preferences stored in Firestore
 * 
 * These settings are synchronized across devices and persist between sessions.
 * Some settings mirror localStorage for backward compatibility.
 * 
 * @interface UserSettings
 */
export interface UserSettings {
  /** Whether to show the download button (mirrors localStorage for compatibility) */
  showDlButton: boolean;
  /** Optional user preferences for caption generation */
  preferences?: {
    /** Default AI providers to use for new images */
    defaultProviders: string[];
    /** Whether to automatically regenerate failed captions */
    autoRegenerate: boolean;
  };
}

/**
 * Configuration for AI vision model providers
 * 
 * Defines how to connect to and interact with different AI vision APIs.
 * 
 * @interface ProviderConfig
 */
export interface ProviderConfig {
  /** Unique identifier for the provider (e.g., "openai", "gemini") */
  id: string;
  /** API endpoint URL for the provider */
  endpoint: string;
  /** Whether this provider is currently enabled */
  enabled: boolean;
  /** Request timeout in milliseconds */
  timeout: number;
}

/**
 * Result returned from a vision provider API call
 * 
 * Standardized response format from all AI vision providers.
 * 
 * @interface CaptionResult
 */
export interface CaptionResult {
  /** Model identifier that generated this caption */
  modelId: string;
  /** The generated caption text */
  caption: string;
  /** Time taken to generate the caption in milliseconds */
  latency: number;
  /** Number of tokens consumed (if available) */
  tokensUsed?: number;
  /** Error message if generation failed */
  error?: string;
}

/**
 * Single entry in the exported dataset JSON file
 * 
 * This is the format used for LoRa training datasets.
 * 
 * @interface DatasetEntry
 * @example
 * ```json
 * {
 *   "url": "https://storage.googleapis.com/bucket/image.jpg",
 *   "filename": "image.jpg", 
 *   "caption": "A golden retriever playing in a park"
 * }
 * ```
 */
export interface DatasetEntry {
  /** Public URL to access the image */
  url: string;
  /** Original filename of the image */
  filename: string;
  /** Selected or edited caption for the image */
  caption: string;
}

/**
 * Progress tracking for batch upload operations
 * 
 * Used to display upload progress and handle batch operations efficiently.
 * 
 * @interface UploadProgress
 */
export interface UploadProgress {
  /** Total number of files in the upload batch */
  total: number;
  /** Number of files successfully uploaded */
  completed: number;
  /** Number of files that failed to upload */
  failed: number;
  /** Number of files currently being uploaded */
  inProgress: number;
}

/**
 * Application-wide configuration settings
 * 
 * Contains Firebase configuration and external service settings.
 * Typically loaded from environment variables.
 * 
 * @interface AppConfig
 */
export interface AppConfig {
  /** Firebase project configuration */
  firebase: {
    /** Firebase API key */
    apiKey: string;
    /** Firebase Auth domain */
    authDomain: string;
    /** Firebase project ID */
    projectId: string;
    /** Firebase Storage bucket */
    storageBucket: string;
    /** Firebase app ID */
    appId: string;
  };
  /** Caption proxy service configuration */
  proxy: {
    /** Base URL for the caption proxy API */
    baseUrl: string;
  };
  /** Available AI vision providers */
  providers: ProviderConfig[];
}

// Re-export validation functions
export * from './validation';

// Re-export utility functions
export * from './utils';